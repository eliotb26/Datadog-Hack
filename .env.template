# ============================================================
# SIGNAL — .env.template
# Self-Improving Content Intelligence Platform
# ============================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control.
# ============================================================


# ------------------------------------------------------------
# GOOGLE DEEPMIND — Core Intelligence Layer
# Gemini API + Agent Development Kit (ADK)
# Get API key: https://aistudio.google.com/apikey
# ADK docs: https://google.github.io/adk-docs/get-started/
# ------------------------------------------------------------
GEMINI_API_KEY=your_gemini_api_key_here
# GOOGLE_API_KEY is the alternative name (takes precedence if both set)
# GOOGLE_API_KEY=your_google_api_key_here

# Set to FALSE to use Gemini API (AI Studio); TRUE to use Vertex AI
GOOGLE_GENAI_USE_VERTEXAI=FALSE

# Required only if using Vertex AI instead of AI Studio
# GOOGLE_CLOUD_PROJECT=your_gcp_project_id
# GOOGLE_CLOUD_LOCATION=us-central1


# ------------------------------------------------------------
# BRAINTRUST — Evaluation & Self-Improvement Engine
# Tracing, Loop Agent, AI Proxy for all LLM calls
# Get API key: https://www.braintrust.dev/app/settings?subroute=api-keys
# Docs: https://www.braintrust.dev/docs/guides/api
# ------------------------------------------------------------
BRAINTRUST_API_KEY=your_braintrust_api_key_here

# Optional: Braintrust project name for organizing traces
BRAINTRUST_PROJECT=signal


# ------------------------------------------------------------
# AIRIA — Enterprise Orchestration & AI Gateway
# Agent Studio workflows, A/B testing (Battleground), constraints
# Sign up: https://airia.com
# Docs: https://explore.airia.com/building-and-deploying-agents/interface-options/api-deployment
# ------------------------------------------------------------
AIRIA_API_KEY=your_airia_api_key_here
AIRIA_PIPELINE_URL=https://api.airia.com/v1/pipelines/your_pipeline_id


# ------------------------------------------------------------
# MODULATE AI — Content Safety & Voice Intelligence
# Two use cases in SIGNAL (see docs/03-sponsor-integrations.md, docs/09-security-safety.md):
#
# 1. ToxMod — Pre-publication content safety
#    Screen campaign headline + body for toxicity before distribution; block if score > SAFETY_THRESHOLD.
#    Appeals API: when humans override a block, feedback is sent to Modulate to improve accuracy.
#    Sign up / docs: https://cloud-console.modulate.ai/
#    SDK docs: https://sdk-docs.modulate.ai/
#
# 2. Velma-2 (optional) — Voice-to-brief for brand voice
#    Companies can record a voice brief ("here's what our brand sounds like"); Modulate transcribes
#    and understands the audio; brand voice signals feed into the Campaign Gen agent.
#    Hackathon: 100 hours free — get API key from Carter on Discord (carterhuffman8385) or #modulate-ai.
#    Endpoints: streaming STT, batch STT, batch english vfast — see Velma-2 OpenAPI .yaml in hackathon_docs.
# ------------------------------------------------------------
MODULATE_API_KEY=your_modulate_api_key_here

# Toxicity score threshold — campaigns scoring above this are blocked (0.0–1.0). Per docs: keep below 0.3.
SAFETY_THRESHOLD=0.3

# Optional: Velma-2 voice API base (only if using voice-brief feature). Leave empty to skip.
# MODULATE_VELMA_BASE_URL=https://modulate-prototype-apis.com


# ------------------------------------------------------------
# FLORA AI — Creative Asset Generation
# 40+ image generation models (FLUX, Stable Diffusion, etc.)
# Sign up: https://www.florafauna.ai/sign-up
# Docs: https://docs.florafauna.ai/more/api
# NOTE: Flora API is currently in early access — request access via docs
# ------------------------------------------------------------
FLORA_API_KEY=your_flora_ai_api_key_here
FLORA_DEFAULT_MODEL=flux-pro
FLORA_DEFAULT_ASPECT_RATIO=16:9


# ------------------------------------------------------------
# DATADOG — Full-Stack Observability
# APM, Logs, Custom Metrics, Monitors & Dashboards
# Get API key: https://app.datadoghq.com/organization-settings/api-keys
# Get APP key: https://app.datadoghq.com/organization-settings/application-keys
# ddtrace docs: https://ddtrace.readthedocs.io/
# ------------------------------------------------------------
DD_API_KEY=your_datadog_api_key_here

# Application key required for Datadog Management API (read operations)
DD_APP_KEY=your_datadog_app_key_here

# Datadog site — use datadoghq.com (US1) or your regional site
# Options: datadoghq.com | us3.datadoghq.com | eu.datadoghq.com | ap1.datadoghq.com
DD_SITE=datadoghq.com

# Service & environment tags (appear in APM and dashboards)
DD_SERVICE=signal-backend
DD_ENV=hackathon
DD_VERSION=0.1.0

# Datadog Agent host — use 'datadog-agent' in Docker Compose, 'localhost' for local dev
DD_AGENT_HOST=datadog-agent

# APM trace intake port
DD_TRACE_AGENT_PORT=8126

# Enable APM tracing
DD_TRACE_ENABLED=true

# Enable runtime metrics (CPU, memory per service)
DD_RUNTIME_METRICS_ENABLED=true

# Enable log injection (correlates logs with traces)
DD_LOGS_INJECTION=true


# ------------------------------------------------------------
# LIGHTDASH — BI Dashboard (Self-Hosted)
# Campaign analytics, agent learning curves, cross-company patterns
# Docs: https://docs.lightdash.com/self-host/self-host-lightdash-docker-compose
# Env vars: https://docs.lightdash.com/self-host/customize-deployment/environment-variables
# WARNING: Never change LIGHTDASH_SECRET after first run — data loss will occur
# ------------------------------------------------------------
LIGHTDASH_SECRET=generate_a_strong_random_secret_here

# Lightdash PostgreSQL database (used by self-hosted Lightdash container)
PGHOST=db
PGPORT=5432
PGUSER=postgres
PGPASSWORD=your_postgres_password_here
PGDATABASE=postgres


# ------------------------------------------------------------
# POLYMARKET — Prediction Market Data Source
# Gamma API (read-only market data) — NO KEY REQUIRED
# Base URL: https://gamma-api.polymarket.com
# Gamma API docs: https://docs.polymarket.com/#gamma-markets-api
#
# CLOB API (authenticated, order-level data) — OPTIONAL
# Required only if you need private market access or order placement.
# Create credentials: https://polymarket.com  (connect wallet → API settings)
# CLOB API docs: https://docs.polymarket.com/#clob-api
# ------------------------------------------------------------

# --- Gamma API (used by Agent 2 Trend Intel — no auth needed) ---
POLYMARKET_BASE_URL=https://gamma-api.polymarket.com

# Volume velocity threshold for filtering high-momentum signals (USD)
POLYMARKET_VOLUME_THRESHOLD=10000

# Polling interval in seconds (how often the Trend Intel Agent polls)
POLYMARKET_POLL_INTERVAL_SECONDS=300

# --- CLOB API credentials (optional — for authenticated / write access) ---
# These are generated from a connected wallet on polymarket.com
POLYMARKET_API_KEY=your_polymarket_clob_api_key_here
POLYMARKET_API_SECRET=your_polymarket_clob_api_secret_here
POLYMARKET_API_PASSPHRASE=your_polymarket_clob_passphrase_here

# CLOB API base URL
POLYMARKET_CLOB_BASE_URL=https://clob.polymarket.com


# ------------------------------------------------------------
# ELEVENLABS — Voice Agent & Text-to-Speech
# Conversational AI, TTS, voice cloning
# Get API key: https://elevenlabs.io/app/settings/api-keys
# Docs: https://elevenlabs.io/docs
# ------------------------------------------------------------
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here


# ------------------------------------------------------------
# APPLICATION CONFIG
# FastAPI backend + React frontend settings
# ------------------------------------------------------------
# Backend
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_URL=http://localhost:3000

# SQLite database path (relative to /app in Docker, or local path for dev)
DATABASE_URL=sqlite+aiosqlite:///./data/signal.db

# Environment: development | hackathon | production
ENVIRONMENT=hackathon

# Logging level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# Autonomous posting trust level (1=human review only, 2=semi-auto, 3=full auto)
AUTONOMOUS_TRUST_LEVEL=1

# Number of campaign concepts to generate per pipeline cycle
CAMPAIGNS_PER_CYCLE=3
